{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:31:23.278027Z",
     "end_time": "2023-07-06T11:31:25.586916Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import glob\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "        subjid  label  shape_Elongation  shape_Flatness   \n0       Oslo01      1          0.829356        0.682981  \\\n1       Oslo01      2          0.944143        0.900681   \n4       Oslo02      4          0.849295        0.841082   \n5       Oslo02      5          0.939828        0.821847   \n7       Oslo03      1          0.930698        0.629604   \n...        ...    ...               ...             ...   \n2408  Stan_328      1          0.810571        0.325076   \n2415  Stan_328      8          0.967496        0.597282   \n2418  Stan_328     11          0.561746        0.506390   \n2419  Stan_328     12          0.959775        0.756903   \n2427  Stan_338      4          0.819799        0.618051   \n\n      shape_LeastAxisLength  shape_MajorAxisLength   \n0                  8.512717              12.464063  \\\n1                 14.133927              15.692487   \n4                  8.703783              10.348315   \n5                 12.093804              14.715396   \n7                 10.914986              17.336268   \n...                     ...                    ...   \n2408               8.769420              26.976501   \n2415               6.131668              10.265944   \n2418               5.004740               9.883181   \n2419               5.164755               6.823538   \n2427               8.548537              13.831433   \n\n      shape_Maximum2DDiameterColumn  shape_Maximum2DDiameterRow   \n0                         14.866069                   14.560220  \\\n1                         17.804494                   19.416488   \n4                         10.816654                   11.704700   \n5                         17.262677                   17.888544   \n7                         20.615528                   18.439089   \n...                             ...                         ...   \n2408                      31.384710                   28.160256   \n2415                      11.661904                   12.369317   \n2418                       8.246211                   11.704700   \n2419                       7.615773                    8.602325   \n2427                      14.142136                   15.297059   \n\n      shape_Maximum2DDiameterSlice  shape_Maximum3DDiameter  ...   \n0                        12.529964                15.394804  ...  \\\n1                        18.681542                19.467922  ...   \n4                        11.704700                12.449900  ...   \n5                        17.492856                18.000000  ...   \n7                        19.416488                20.712315  ...   \n...                            ...                      ...  ...   \n2408                     27.459060                33.075671  ...   \n2415                     12.165525                12.688578  ...   \n2418                     10.000000                12.124356  ...   \n2419                      8.602325                 8.602325  ...   \n2427                     17.204651                17.291616  ...   \n\n      ngtdm_Busyness  ngtdm_Coarseness  ngtdm_Complexity  ngtdm_Contrast   \n0         158.977235          0.008929          0.302273        0.074659  \\\n1          39.445794          0.007407          0.115448        0.010426   \n4          14.239428          0.022868          0.159307        0.020316   \n5          49.609354          0.008536          0.137901        0.028455   \n7          43.648474          0.007781          0.123220        0.017415   \n...              ...               ...               ...             ...   \n2408       12.988427          0.019891          0.030104        0.000639   \n2415       18.452502          0.024791          0.208465        0.046975   \n2418        0.553323          0.468447          0.025263        0.000748   \n2419        0.000000    1000000.000000          0.000000        0.000000   \n2427        6.977967          0.040814          0.057854        0.005610   \n\n      ngtdm_Strength  Age  number_annotations  F  M  labels  \n0           0.008950   58                   1  0  1       0  \n1           0.007130   58                   1  0  1       0  \n4           0.023465   50                   1  1  0       1  \n5           0.008212   50                   1  1  0       1  \n7           0.007982   64                   1  0  1       0  \n...              ...  ...                 ... .. ..     ...  \n2408        0.019768   53                   1  0  1       1  \n2415        0.023205   53                   1  0  1       1  \n2418        0.365681   53                   1  0  1       1  \n2419        0.000000   53                   1  0  1       1  \n2427        0.031493   42                   1  1  0       1  \n\n[438 rows x 114 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subjid</th>\n      <th>label</th>\n      <th>shape_Elongation</th>\n      <th>shape_Flatness</th>\n      <th>shape_LeastAxisLength</th>\n      <th>shape_MajorAxisLength</th>\n      <th>shape_Maximum2DDiameterColumn</th>\n      <th>shape_Maximum2DDiameterRow</th>\n      <th>shape_Maximum2DDiameterSlice</th>\n      <th>shape_Maximum3DDiameter</th>\n      <th>...</th>\n      <th>ngtdm_Busyness</th>\n      <th>ngtdm_Coarseness</th>\n      <th>ngtdm_Complexity</th>\n      <th>ngtdm_Contrast</th>\n      <th>ngtdm_Strength</th>\n      <th>Age</th>\n      <th>number_annotations</th>\n      <th>F</th>\n      <th>M</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Oslo01</td>\n      <td>1</td>\n      <td>0.829356</td>\n      <td>0.682981</td>\n      <td>8.512717</td>\n      <td>12.464063</td>\n      <td>14.866069</td>\n      <td>14.560220</td>\n      <td>12.529964</td>\n      <td>15.394804</td>\n      <td>...</td>\n      <td>158.977235</td>\n      <td>0.008929</td>\n      <td>0.302273</td>\n      <td>0.074659</td>\n      <td>0.008950</td>\n      <td>58</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Oslo01</td>\n      <td>2</td>\n      <td>0.944143</td>\n      <td>0.900681</td>\n      <td>14.133927</td>\n      <td>15.692487</td>\n      <td>17.804494</td>\n      <td>19.416488</td>\n      <td>18.681542</td>\n      <td>19.467922</td>\n      <td>...</td>\n      <td>39.445794</td>\n      <td>0.007407</td>\n      <td>0.115448</td>\n      <td>0.010426</td>\n      <td>0.007130</td>\n      <td>58</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oslo02</td>\n      <td>4</td>\n      <td>0.849295</td>\n      <td>0.841082</td>\n      <td>8.703783</td>\n      <td>10.348315</td>\n      <td>10.816654</td>\n      <td>11.704700</td>\n      <td>11.704700</td>\n      <td>12.449900</td>\n      <td>...</td>\n      <td>14.239428</td>\n      <td>0.022868</td>\n      <td>0.159307</td>\n      <td>0.020316</td>\n      <td>0.023465</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Oslo02</td>\n      <td>5</td>\n      <td>0.939828</td>\n      <td>0.821847</td>\n      <td>12.093804</td>\n      <td>14.715396</td>\n      <td>17.262677</td>\n      <td>17.888544</td>\n      <td>17.492856</td>\n      <td>18.000000</td>\n      <td>...</td>\n      <td>49.609354</td>\n      <td>0.008536</td>\n      <td>0.137901</td>\n      <td>0.028455</td>\n      <td>0.008212</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Oslo03</td>\n      <td>1</td>\n      <td>0.930698</td>\n      <td>0.629604</td>\n      <td>10.914986</td>\n      <td>17.336268</td>\n      <td>20.615528</td>\n      <td>18.439089</td>\n      <td>19.416488</td>\n      <td>20.712315</td>\n      <td>...</td>\n      <td>43.648474</td>\n      <td>0.007781</td>\n      <td>0.123220</td>\n      <td>0.017415</td>\n      <td>0.007982</td>\n      <td>64</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2408</th>\n      <td>Stan_328</td>\n      <td>1</td>\n      <td>0.810571</td>\n      <td>0.325076</td>\n      <td>8.769420</td>\n      <td>26.976501</td>\n      <td>31.384710</td>\n      <td>28.160256</td>\n      <td>27.459060</td>\n      <td>33.075671</td>\n      <td>...</td>\n      <td>12.988427</td>\n      <td>0.019891</td>\n      <td>0.030104</td>\n      <td>0.000639</td>\n      <td>0.019768</td>\n      <td>53</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2415</th>\n      <td>Stan_328</td>\n      <td>8</td>\n      <td>0.967496</td>\n      <td>0.597282</td>\n      <td>6.131668</td>\n      <td>10.265944</td>\n      <td>11.661904</td>\n      <td>12.369317</td>\n      <td>12.165525</td>\n      <td>12.688578</td>\n      <td>...</td>\n      <td>18.452502</td>\n      <td>0.024791</td>\n      <td>0.208465</td>\n      <td>0.046975</td>\n      <td>0.023205</td>\n      <td>53</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2418</th>\n      <td>Stan_328</td>\n      <td>11</td>\n      <td>0.561746</td>\n      <td>0.506390</td>\n      <td>5.004740</td>\n      <td>9.883181</td>\n      <td>8.246211</td>\n      <td>11.704700</td>\n      <td>10.000000</td>\n      <td>12.124356</td>\n      <td>...</td>\n      <td>0.553323</td>\n      <td>0.468447</td>\n      <td>0.025263</td>\n      <td>0.000748</td>\n      <td>0.365681</td>\n      <td>53</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2419</th>\n      <td>Stan_328</td>\n      <td>12</td>\n      <td>0.959775</td>\n      <td>0.756903</td>\n      <td>5.164755</td>\n      <td>6.823538</td>\n      <td>7.615773</td>\n      <td>8.602325</td>\n      <td>8.602325</td>\n      <td>8.602325</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1000000.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>53</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2427</th>\n      <td>Stan_338</td>\n      <td>4</td>\n      <td>0.819799</td>\n      <td>0.618051</td>\n      <td>8.548537</td>\n      <td>13.831433</td>\n      <td>14.142136</td>\n      <td>15.297059</td>\n      <td>17.204651</td>\n      <td>17.291616</td>\n      <td>...</td>\n      <td>6.977967</td>\n      <td>0.040814</td>\n      <td>0.057854</td>\n      <td>0.005610</td>\n      <td>0.031493</td>\n      <td>42</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>438 rows × 114 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('all_patients.xlsx')\n",
    "df = df[df.shape_VoxelVolume > 125]\n",
    "df.drop(df[df['labels'] == 3].index, inplace = True) ## dropping label of the call OTHERS\n",
    "df.drop(df[df['number_annotations'] > 1].index, inplace = True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:31:28.488175Z",
     "end_time": "2023-07-06T11:31:31.320702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        Subjid  Tumor  Labels\n0       Oslo01      1       0\n4       Oslo02      4       1\n7       Oslo03      1       0\n11      Oslo04      1       0\n13      Oslo06      1       1\n...        ...    ...     ...\n2359  Stan_318      1       1\n2369  Stan_319      2       1\n2387  Stan_323      3       1\n2408  Stan_328      1       1\n2427  Stan_338      4       1\n\n[158 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subjid</th>\n      <th>Tumor</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Oslo01</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oslo02</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Oslo03</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Oslo04</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Oslo06</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2359</th>\n      <td>Stan_318</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2369</th>\n      <td>Stan_319</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2387</th>\n      <td>Stan_323</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2408</th>\n      <td>Stan_328</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2427</th>\n      <td>Stan_338</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>158 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame({'Subjid': df.iloc[:, 0], 'Tumor': df.iloc[:, 1], 'Labels': df.iloc[:, -1]})\n",
    "new_df = new_df.drop_duplicates(subset='Subjid', keep='first')\n",
    "#new_df.to_excel('labels_DL.xlsx', index = False)\n",
    "new_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:31:41.793869Z",
     "end_time": "2023-07-06T11:31:41.797178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "stan = new_df['Subjid'][59:].to_list()\n",
    "oslo = new_df['Subjid'][:59].to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:31:49.211766Z",
     "end_time": "2023-07-06T11:31:49.215024Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## we have created a new folder called deep learning with all the folder with all the folder per patient labels as 0, 1 or 2 with tumors greater than 125mm3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [],
   "source": [
    "# Specify the path to the parent folder\n",
    "parent_folder = '/data/projects/TMOR/data/Deeplearning/'\n",
    "\n",
    "# Get a list of all subfolders within the parent folder\n",
    "subfolders = [f.path for f in os.scandir(parent_folder) if f.is_dir()]\n",
    "\n",
    "# Iterate over the subfolders and rename them\n",
    "\n",
    "for folder in subfolders:\n",
    "    folder_name = os.path.basename(folder)\n",
    "    new_folder_name = folder_name.replace(\"Subject\", \"Oslo\")\n",
    "    #new_folder_name = folder_name.replace(\"Mets\", \"Stan\")\n",
    "    new_folder_path = os.path.join(parent_folder, new_folder_name)\n",
    "    os.rename(folder, new_folder_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T17:47:59.313418Z",
     "end_time": "2023-06-19T17:47:59.341160Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "#delete the other file for OSLO\n",
    "directory = '/data/projects/TMOR/data/Deeplearning/'\n",
    "\n",
    "# Get a list of all patient folders\n",
    "patient_folders = glob.glob(os.path.join(directory, 'Oslo*'))\n",
    "\n",
    "for patient_folder in patient_folders:\n",
    "    #id = patient_folder[-2:]\n",
    "    seg_folders = glob.glob(os.path.join(patient_folder, 'seg*'))\n",
    "    t1_gds = glob.glob(os.path.join(patient_folder, 't1_gd*'))\n",
    "    #print(seg_folders)\n",
    "    # Iterate over each seg folder\n",
    "    for seg_folder in seg_folders:\n",
    "        for t1_gd in t1_gds:\n",
    "            #print(seg_folder)\n",
    "            image_files = glob.glob(os.path.join(patient_folder, '*'))\n",
    "            #print(image_files)\n",
    "            # Delete all the image files except for 'seg_1'\n",
    "            for file in image_files:\n",
    "            # Check if the file is in the segmentation folder or T1-Gd folder\n",
    "                if file not in [seg_folder, t1_gd]:\n",
    "                    os.remove(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T17:48:07.240665Z",
     "end_time": "2023-06-19T17:48:07.380290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [],
   "source": [
    "patient_folders = glob.glob(os.path.join(directory, 'Oslo*'))\n",
    "import shutil\n",
    "for patient_folder in patient_folders:\n",
    "    id = patient_folder[-6:]\n",
    "    if id not in oslo:\n",
    "        shutil.rmtree(patient_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T17:48:30.041220Z",
     "end_time": "2023-06-19T17:48:30.067252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = '/data/projects/TMOR/data/Deeplearning/'\n",
    "\n",
    "patient_folders = glob.glob(os.path.join(directory, 'Oslo*'))\n",
    "\n",
    "\n",
    "# Iterate over patient folders\n",
    "for patient_folder in patient_folders:\n",
    "    #patient_path = os.path.join(directory, patient_folder)\n",
    "    seg_folders = glob.glob(os.path.join(patient_folder, 'seg*'))\n",
    "    # Rename segmentation files\n",
    "    for seg_folder in seg_folders:\n",
    "        seg_old_path = seg_folder\n",
    "        seg_new_path = os.path.join(patient_folder, 'seg.nii.gz')\n",
    "        os.rename(seg_old_path, seg_new_path)\n",
    "        #print(seg_new_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-20T21:41:11.352413Z",
     "end_time": "2023-06-20T21:41:11.359538Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STANDFORD DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [],
   "source": [
    "# Specify the path to the parent folder\n",
    "parent_folder = '/data/projects/TMOR/data/Deeplearning/'\n",
    "\n",
    "# Get a list of all subfolders within the parent folder\n",
    "subfolders = [f.path for f in os.scandir(parent_folder) if f.is_dir()]\n",
    "\n",
    "# Iterate over the subfolders and rename them\n",
    "\n",
    "for folder in subfolders:\n",
    "    folder_name = os.path.basename(folder)\n",
    "    new_folder_name = folder_name.replace(\"Mets\", \"Stan\")\n",
    "    new_folder_path = os.path.join(parent_folder, new_folder_name)\n",
    "    os.rename(folder, new_folder_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T17:51:09.426017Z",
     "end_time": "2023-06-19T17:51:09.465564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#delete the other file for OSLO\n",
    "directory = '/data/projects/TMOR/data/Deeplearning/'\n",
    "\n",
    "# Get a list of all patient folders\n",
    "patient_folders = glob.glob(os.path.join(directory, 'Stan*'))\n",
    "\n",
    "for patient_folder in patient_folders:\n",
    "    seg_folders = glob.glob(os.path.join(patient_folder, 'seg*'))\n",
    "    t1_gds = glob.glob(os.path.join(patient_folder, 't1_gd*'))\n",
    "    # Iterate over each seg folder\n",
    "    for seg_folder in seg_folders:\n",
    "        for t1_gd in t1_gds:\n",
    "            image_files = glob.glob(os.path.join(patient_folder, '*'))\n",
    "            # Delete all the image files except for 'seg_1'\n",
    "            for file in image_files:\n",
    "                # Check if the file is in the segmentation folder or T1-Gd folder\n",
    "                if file not in [seg_folder, t1_gd]:\n",
    "                    os.remove(file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T17:51:13.837773Z",
     "end_time": "2023-06-19T17:51:14.245613Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "#Remove all the files that are not within stan\n",
    "import shutil\n",
    "for patient_folder in patient_folders:\n",
    "    id = patient_folder[-8:]\n",
    "    if id not in stan:\n",
    "        shutil.rmtree(patient_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T17:51:18.497052Z",
     "end_time": "2023-06-19T17:51:18.561806Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## move all t1_pre to the right folder of /data/projects/TMOR/data/Deeplearning/A/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OSLO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Specify the path to the parent folder\n",
    "parent_folder = '/data/projects/TMOR/data/OsloPreprocessed/OsloPreprocessed/'\n",
    "\n",
    "# Get a list of all subfolders within the parent folder\n",
    "subfolders = [f.path for f in os.scandir(parent_folder) if f.is_dir()]\n",
    "\n",
    "# Iterate over the subfolders and rename them\n",
    "\n",
    "for folder in subfolders:\n",
    "    folder_name = os.path.basename(folder)\n",
    "    new_folder_name = folder_name.replace(\"Subject\", \"Oslo\")\n",
    "    #new_folder_name = folder_name.replace(\"Mets\", \"Stan\")\n",
    "    new_folder_path = os.path.join(parent_folder, new_folder_name)\n",
    "    os.rename(folder, new_folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:55:52.166448Z",
     "end_time": "2023-07-06T11:55:52.181085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import shutil\n",
    "directory = '/data/projects/TMOR/data/OsloPreprocessed/OsloPreprocessed/'\n",
    "\n",
    "patient_folders = glob.glob(os.path.join(directory, 'Oslo*'))\n",
    "\n",
    "repository = '/data/projects/TMOR/data/Deeplearning/'\n",
    "\n",
    "pacientes = glob.glob(os.path.join(repository, 'Oslo*'))\n",
    "\n",
    "for patient_folder in patient_folders:\n",
    "    t1_pre_files = glob.glob(os.path.join(patient_folder, 't1_pre*'))\n",
    "    for t1 in t1_pre_files:\n",
    "        patient_id = os.path.basename(patient_folder)\n",
    "        patient_match = next((p for p in pacientes if patient_id in p), None)\n",
    "        if patient_match:\n",
    "        # Move each t1-pre file to the respective patient folder\n",
    "            for t1_pre_file in t1_pre_files:\n",
    "                destination_folder = os.path.join(patient_match, os.path.basename(t1_pre_file))\n",
    "                shutil.copy(t1_pre_file, destination_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T12:08:01.073832Z",
     "end_time": "2023-07-06T12:08:02.492279Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standford"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Specify the path to the parent folder\n",
    "parent_folder = '/data/projects/TMOR/data/StanfordPreprocessed/StanfordPreprocessed/'\n",
    "\n",
    "# Get a list of all subfolders within the parent folder\n",
    "subfolders = [f.path for f in os.scandir(parent_folder) if f.is_dir()]\n",
    "\n",
    "# Iterate over the subfolders and rename them\n",
    "\n",
    "for folder in subfolders:\n",
    "    folder_name = os.path.basename(folder)\n",
    "    #new_folder_name = folder_name.replace(\"Subject\", \"Oslo\")\n",
    "    new_folder_name = folder_name.replace(\"Mets\", \"Stan\")\n",
    "    new_folder_path = os.path.join(parent_folder, new_folder_name)\n",
    "    os.rename(folder, new_folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T12:15:15.366395Z",
     "end_time": "2023-07-06T12:15:15.406773Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "directory = '/data/projects/TMOR/data/StanfordPreprocessed/StanfordPreprocessed/'\n",
    "\n",
    "patient_folders = glob.glob(os.path.join(directory, 'Stan*'))\n",
    "\n",
    "repository = '/data/projects/TMOR/data/Deeplearning/'\n",
    "\n",
    "pacientes = glob.glob(os.path.join(repository, 'Stan*'))\n",
    "\n",
    "for patient_folder in patient_folders:\n",
    "    t1_pre_files = glob.glob(os.path.join(patient_folder, 't1_pre*'))\n",
    "    for t1 in t1_pre_files:\n",
    "        patient_id = os.path.basename(patient_folder)\n",
    "        patient_match = next((p for p in pacientes if patient_id in p), None)\n",
    "        if patient_match:\n",
    "        # Move each t1-pre file to the respective patient folder\n",
    "            for t1_pre_file in t1_pre_files:\n",
    "                destination_folder = os.path.join(patient_match, os.path.basename(t1_pre_file))\n",
    "                shutil.copy(t1_pre_file, destination_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T12:16:31.730909Z",
     "end_time": "2023-07-06T12:16:33.740620Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## class object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344\n",
      "1344\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 103\u001B[0m\n\u001B[1;32m    100\u001B[0m labels_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels_DL.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    101\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([transforms\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m)), transforms\u001B[38;5;241m.\u001B[39mToTensor()])\n\u001B[0;32m--> 103\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mBrainSegmentationDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m data_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[34], line 21\u001B[0m, in \u001B[0;36mBrainSegmentationDataset.__init__\u001B[0;34m(self, img_dir, labels_file, transform, target_transform)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;241m=\u001B[39m transform\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;241m=\u001B[39m target_transform\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_test, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_train, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[34], line 61\u001B[0m, in \u001B[0;36mBrainSegmentationDataset.split_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     57\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_labels\u001B[38;5;241m.\u001B[39miloc[:, \u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     59\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, stratify\u001B[38;5;241m=\u001B[39my, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 61\u001B[0m X_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m X_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_images(X_test)\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X_train, X_test, y_train, y_test\n",
      "Cell \u001B[0;32mIn[34], line 89\u001B[0m, in \u001B[0;36mBrainSegmentationDataset.process_images\u001B[0;34m(self, image_names)\u001B[0m\n\u001B[1;32m     86\u001B[0m end \u001B[38;5;241m=\u001B[39m start \u001B[38;5;241m+\u001B[39m max_tumor_size\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m# Crop image and mask tensors\u001B[39;00m\n\u001B[0;32m---> 89\u001B[0m data \u001B[38;5;241m=\u001B[39m data[\u001B[43mstart\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m:end[\u001B[38;5;241m0\u001B[39m], start[\u001B[38;5;241m1\u001B[39m]:end[\u001B[38;5;241m1\u001B[39m], start[\u001B[38;5;241m2\u001B[39m]:end[\u001B[38;5;241m2\u001B[39m]]\n\u001B[1;32m     90\u001B[0m mask \u001B[38;5;241m=\u001B[39m mask[start[\u001B[38;5;241m0\u001B[39m]:end[\u001B[38;5;241m0\u001B[39m], start[\u001B[38;5;241m1\u001B[39m]:end[\u001B[38;5;241m1\u001B[39m], start[\u001B[38;5;241m2\u001B[39m]:end[\u001B[38;5;241m2\u001B[39m]]\n\u001B[1;32m     92\u001B[0m data_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(data)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "def crop_to_largest_tumor(tensor, crop_size):\n",
    "    # Get tumor dimensions\n",
    "    tumor_size = np.sum(tensor > 0, axis=(1, 2, 3))\n",
    "    max_tumor_size = np.max(tumor_size)\n",
    "\n",
    "    # Calculate cropping indices\n",
    "    start = (tumor_size - max_tumor_size) // 2\n",
    "    end = start + max_tumor_size\n",
    "\n",
    "    # Perform cropping\n",
    "    cropped_tensor = tensor[:, start:end, start:end, start:end]\n",
    "\n",
    "    return cropped_tensor\n",
    "class BrainSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.read_excel(labels_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.split_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the mask directly\n",
    "        seg_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 'seg.nii.gz')\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 't1_gd.nii.gz')\n",
    "        data_1 = nib.load(img_path)\n",
    "        data = data_1.get_fdata()\n",
    "        mask_1 = nib.load(seg_path)\n",
    "        mask = mask_1.get_fdata()\n",
    "        label = self.y_train[idx]\n",
    "\n",
    "        data = torch.from_numpy(data).unsqueeze(0)\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "        label = torch.tensor(label).long()\n",
    "\n",
    "        return mask, data, label\n",
    "\n",
    "    def split_data(self):\n",
    "        X = self.img_labels.iloc[:, 0].values\n",
    "        y = self.img_labels.iloc[:, 2].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "        X_train = self.process_images(X_train)\n",
    "        X_test = self.process_images(X_test)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def process_images(self, image_names):\n",
    "        image_tensors = []\n",
    "\n",
    "        for image_name in image_names:\n",
    "            # Load the mask directly\n",
    "            seg_path = os.path.join(self.img_dir, image_name, 'seg.nii.gz')\n",
    "            img_path = os.path.join(self.img_dir, image_name, 't1_gd.nii.gz')\n",
    "            data_1 = nib.load(img_path)\n",
    "            data = data_1.get_fdata()\n",
    "            mask_1 = nib.load(seg_path)\n",
    "            mask = mask_1.get_fdata()\n",
    "\n",
    "            data_tensor = torch.from_numpy(data).unsqueeze(0)\n",
    "            mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "            image_tensors.append((data_tensor, mask_tensor))\n",
    "\n",
    "        return image_tensors\n",
    "\n",
    "            tumor_size = np.sum(mask > 0, axis=(0, 1, 2))\n",
    "            print(tumor_size)\n",
    "            max_tumor_size = np.max(tumor_size)\n",
    "            print(max_tumor_size)\n",
    "\n",
    "            # Calculate cropping indices\n",
    "            start = (tumor_size - max_tumor_size) // 2\n",
    "            print(start)\n",
    "            end = start + max_tumor_size\n",
    "\n",
    "            # Crop image and mask tensors\n",
    "            data = data[start[0]:end[0], start[1]:end[1], start[2]:end[2]]\n",
    "            mask = mask[start[0]:end[0], start[1]:end[1], start[2]:end[2]]\n",
    "\n",
    "            data_tensor = torch.from_numpy(data).unsqueeze(0)\n",
    "            mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "            image_tensors.append((data_tensor, mask_tensor))\n",
    "\n",
    "        return image_tensors\n",
    "\n",
    "img_dir = '/data/projects/TMOR/data/Deeplearning/'\n",
    "labels_file = 'labels_DL.xlsx'\n",
    "transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "\n",
    "dataset = BrainSegmentationDataset(img_dir, labels_file, transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T20:46:34.373136Z",
     "end_time": "2023-06-19T20:47:15.555267Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## lets divide the tumors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "D_x_max, D_y_max, D_z_max = 0, 0, 0\n",
    "seg_dir = '/data/projects/TMOR/data/Deeplearning/'\n",
    "#indices = []\n",
    "for subj_id in os.listdir(seg_dir):\n",
    "    #extrasct the correct id from the subjects\n",
    "    # Define paths to the segmentation and regular t1 postprocessed files for this subject\n",
    "    seg_glob = os.path.join(seg_dir, f'{subj_id}', f'seg.nii.gz')\n",
    "    reg_glob = os.path.join(seg_dir, f'{subj_id}', f't1_gd.nii.gz')\n",
    "    seg_paths = glob.glob(seg_glob)\n",
    "    reg_paths = glob.glob(reg_glob)\n",
    "    # Loop through all matching segmentation and registration files\n",
    "    for seg, reg in zip(seg_paths, reg_paths):\n",
    "        if os.path.exists(seg) and os.path.exists(reg):\n",
    "            mask = nib.load(seg)\n",
    "            vol_mask = mask.get_fdata()\n",
    "            for label in np.unique(vol_mask):\n",
    "                if label != 0:\n",
    "                    label_indices = np.argwhere(vol_mask == label)\n",
    "                    if len(label_indices) > 125:\n",
    "                        indices = label_indices\n",
    "                        X_min, X_max = np.min(indices[:, 0]), np.max(indices[:, 0])\n",
    "                        Y_min, Y_max = np.min(indices[:, 1]), np.max(indices[:, 1])\n",
    "                        Z_min, Z_max = np.min(indices[:, 2]), np.max(indices[:, 2])\n",
    "                        #we need the differences now boi\n",
    "                        D_x = X_max - X_min\n",
    "                        D_y = Y_max - Y_min\n",
    "                        D_z = Z_max - Z_min\n",
    "                        if D_x_max < D_x:\n",
    "                        \tD_x_max = D_x\n",
    "                        if D_y_max < D_y:\n",
    "                        \tD_y_max = D_y\n",
    "                        if D_z_max < D_z:\n",
    "                        \tD_z_max = D_z"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:32:35.365587Z",
     "end_time": "2023-07-06T15:33:56.863759Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "drop_dir = '/data/projects/TMOR/data/'\n",
    "seg_dir = '/data/projects/TMOR/data/Deeplearning/'\n",
    "#indices = []\n",
    "for subj_id in os.listdir(seg_dir):\n",
    "    #extrasct the correct id from the subjects\n",
    "    # Define paths to the segmentation and regular t1 postprocessed files for this subject\n",
    "    seg_glob = os.path.join(seg_dir, f'{subj_id}', f'seg.nii.gz')\n",
    "    reg_glob = os.path.join(seg_dir, f'{subj_id}', f't1_gd.nii.gz')\n",
    "    reg2_glob = os.path.join(seg_dir, f'{subj_id}', f't1_pre.nii.gz')\n",
    "    seg_paths = glob.glob(seg_glob)\n",
    "    reg_paths = glob.glob(reg_glob)\n",
    "    reg2_paths = glob.glob(reg2_glob)\n",
    "    # Loop through all matching segmentation and registration files\n",
    "    for seg, reg, reg2 in zip(seg_paths, reg_paths, reg2_paths):\n",
    "        if os.path.exists(seg) and os.path.exists(reg) and os.path.exists(reg2):\n",
    "            mask = nib.load(seg)\n",
    "            vol_mask = mask.get_fdata()\n",
    "            t1_gd = nib.load(reg)\n",
    "            vol_t1_gd = t1_gd.get_fdata()\n",
    "            t1_pre = nib.load(reg2)\n",
    "            vol_t1_pre = t1_pre.get_fdata()\n",
    "            for label in np.unique(vol_mask):\n",
    "                if label != 0:\n",
    "                    label_indices = np.argwhere(vol_mask == label)\n",
    "                    if len(label_indices) > 125:\n",
    "                        indices = label_indices\n",
    "                        X_min, X_max = np.min(indices[:, 0]), np.max(indices[:, 0])\n",
    "                        Y_min, Y_max = np.min(indices[:, 1]), np.max(indices[:, 1])\n",
    "                        Z_min, Z_max = np.min(indices[:, 2]), np.max(indices[:, 2])\n",
    "\n",
    "                        X_avg = (X_min + X_max) // 2\n",
    "                        Y_avg = (Y_min + Y_max) // 2\n",
    "                        Z_avg = (Z_min + Z_max) // 2\n",
    "                        # Pad the indices with zeros\n",
    "                        X_low = max(X_avg - (D_x_max // 2), 0)\n",
    "                        X_high = min(X_avg + (D_x_max // 2), vol_mask.shape[0])\n",
    "                        Y_low = max(Y_avg - (D_y_max // 2), 0)\n",
    "                        Y_high = min(Y_avg + (D_y_max // 2), vol_mask.shape[1])\n",
    "                        Z_low = max(Z_avg - (D_z_max // 2), 0)\n",
    "                        Z_high = min(Z_avg + (D_z_max // 2), vol_mask.shape[2])\n",
    "\n",
    "                        pene = vol_mask[X_low:X_high, Y_low:Y_high, Z_low:Z_high]\n",
    "                        t1_desp = vol_t1_gd[X_low:X_high, Y_low:Y_high, Z_low:Z_high]\n",
    "                        t1_antes = vol_t1_pre[X_low:X_high, Y_low:Y_high, Z_low:Z_high]\n",
    "\n",
    "                        ## define the pads\n",
    "                        pad_width = [\n",
    "                            (0, max(D_x_max - pene.shape[0], 0)),\n",
    "                            (0, max(D_y_max - pene.shape[1], 0)),\n",
    "                            (0, max(D_z_max - pene.shape[2], 0))\n",
    "                        ]\n",
    "                        # define the partitions\n",
    "                        seg_partitioned = np.pad(pene, pad_width, mode='constant', constant_values=0)\n",
    "                        t1_gd_partitioned = np.pad(t1_desp, pad_width, mode='constant', constant_values=0)\n",
    "                        t1_pre_partitioned = np.pad(t1_antes, pad_width, mode='constant', constant_values=0)\n",
    "                        #\n",
    "                        output_dir = os.path.join(drop_dir, 'VeryFinal', subj_id, str(int(label)))\n",
    "                        os.makedirs(output_dir, exist_ok=True)\n",
    "                        # tumors segemented of the segmentation of mask\n",
    "                        output_path_1 = os.path.join(output_dir, 'seg.nii.gz')\n",
    "                        nib.save(nib.Nifti1Image(seg_partitioned, mask.affine), output_path_1)\n",
    "                        # tumors segmented of the t1_gd\n",
    "                        output_path_2 = os.path.join(output_dir, 't1_gd.nii.gz')\n",
    "                        nib.save(nib.Nifti1Image(t1_gd_partitioned, t1_gd.affine), output_path_2)\n",
    "                        # tumors segemented if t1_pre\n",
    "                        output_path_3 = os.path.join(output_dir, 't1_pre.nii.gz')\n",
    "                        nib.save(nib.Nifti1Image(t1_pre_partitioned, t1_pre.affine), output_path_3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T15:34:54.740170Z",
     "end_time": "2023-07-06T15:37:02.430156Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 169, 141)\n",
      "(152, 186, 143)\n",
      "(145, 176, 140)\n",
      "(133, 152, 126)\n",
      "(138, 164, 137)\n",
      "(132, 167, 137)\n",
      "(130, 169, 139)\n",
      "(143, 164, 142)\n",
      "(142, 177, 141)\n",
      "(157, 184, 148)\n",
      "(138, 167, 138)\n",
      "(126, 166, 120)\n",
      "(138, 182, 141)\n",
      "(142, 176, 135)\n",
      "(143, 170, 141)\n",
      "(138, 166, 125)\n",
      "(139, 170, 132)\n",
      "(142, 170, 136)\n",
      "(138, 174, 132)\n",
      "(130, 156, 132)\n",
      "(140, 163, 137)\n",
      "(149, 177, 139)\n",
      "(132, 151, 129)\n",
      "(132, 162, 132)\n",
      "(135, 162, 127)\n",
      "(140, 160, 135)\n",
      "(140, 171, 125)\n",
      "(140, 163, 141)\n",
      "(130, 169, 133)\n",
      "(143, 165, 130)\n",
      "(142, 154, 135)\n",
      "(139, 169, 140)\n",
      "(148, 168, 143)\n",
      "(140, 159, 137)\n",
      "(134, 167, 134)\n",
      "(138, 169, 132)\n",
      "(139, 166, 135)\n",
      "(134, 160, 129)\n",
      "(143, 179, 143)\n",
      "(144, 185, 140)\n",
      "(130, 176, 136)\n",
      "(135, 165, 128)\n",
      "(137, 175, 129)\n",
      "(147, 169, 131)\n",
      "(139, 168, 135)\n",
      "(138, 172, 132)\n",
      "(132, 163, 131)\n",
      "(147, 171, 140)\n",
      "(145, 177, 147)\n",
      "(146, 173, 143)\n",
      "(142, 170, 135)\n",
      "(141, 180, 140)\n",
      "(124, 162, 129)\n",
      "(150, 180, 148)\n",
      "(148, 175, 143)\n",
      "(130, 182, 137)\n",
      "(143, 179, 136)\n",
      "(138, 160, 143)\n",
      "(131, 159, 133)\n",
      "(133, 157, 135)\n",
      "(130, 166, 128)\n",
      "(130, 161, 126)\n",
      "(135, 159, 132)\n",
      "(135, 164, 132)\n",
      "(141, 165, 133)\n",
      "(132, 171, 128)\n",
      "(133, 159, 121)\n",
      "(133, 171, 128)\n",
      "(139, 154, 136)\n",
      "(127, 172, 136)\n",
      "(136, 166, 137)\n",
      "(132, 165, 128)\n",
      "(143, 162, 136)\n",
      "(135, 163, 130)\n",
      "(123, 159, 135)\n",
      "(133, 164, 129)\n",
      "(130, 154, 142)\n",
      "(141, 152, 141)\n",
      "(125, 160, 132)\n",
      "(130, 162, 128)\n",
      "(135, 175, 138)\n",
      "(142, 163, 127)\n",
      "(130, 157, 130)\n",
      "(130, 160, 130)\n",
      "(139, 155, 129)\n",
      "(137, 168, 134)\n",
      "(127, 179, 132)\n",
      "(133, 166, 133)\n",
      "(127, 179, 140)\n",
      "(133, 154, 143)\n",
      "(138, 147, 134)\n",
      "(145, 157, 136)\n",
      "(140, 158, 133)\n",
      "(145, 169, 140)\n",
      "(127, 163, 122)\n",
      "(133, 152, 134)\n",
      "(129, 168, 136)\n",
      "(127, 156, 127)\n",
      "(143, 161, 138)\n",
      "(127, 159, 138)\n",
      "(140, 157, 128)\n",
      "(139, 166, 138)\n",
      "(138, 157, 134)\n",
      "(133, 151, 125)\n",
      "(136, 176, 136)\n",
      "(129, 179, 140)\n",
      "(133, 166, 131)\n",
      "(136, 180, 146)\n",
      "(132, 170, 131)\n",
      "(127, 169, 137)\n",
      "(142, 184, 137)\n",
      "(137, 163, 136)\n",
      "(138, 176, 125)\n",
      "(133, 166, 129)\n",
      "(136, 175, 136)\n",
      "(147, 157, 130)\n",
      "(148, 157, 130)\n",
      "(136, 167, 137)\n",
      "(148, 157, 140)\n",
      "(135, 162, 138)\n",
      "(131, 159, 125)\n",
      "(135, 145, 135)\n",
      "(138, 160, 141)\n",
      "(136, 160, 130)\n",
      "(146, 179, 139)\n",
      "(130, 170, 148)\n",
      "(133, 157, 133)\n",
      "(128, 160, 145)\n",
      "(127, 162, 133)\n",
      "(141, 173, 151)\n",
      "(125, 161, 134)\n",
      "(130, 160, 130)\n",
      "(137, 154, 133)\n",
      "(127, 162, 126)\n",
      "(129, 161, 138)\n",
      "(131, 167, 124)\n",
      "(135, 158, 134)\n",
      "(138, 156, 137)\n",
      "(136, 173, 137)\n",
      "(145, 185, 132)\n",
      "(143, 160, 137)\n",
      "(130, 166, 129)\n",
      "(131, 167, 133)\n",
      "(136, 157, 126)\n",
      "(134, 163, 127)\n",
      "(138, 173, 138)\n",
      "(131, 177, 131)\n",
      "(131, 159, 136)\n",
      "(140, 159, 138)\n",
      "(143, 147, 130)\n",
      "(141, 150, 132)\n",
      "(144, 164, 134)\n",
      "(151, 169, 134)\n",
      "(131, 180, 146)\n",
      "(144, 181, 142)\n",
      "(135, 152, 138)\n",
      "(127, 162, 130)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def clamp(num, mn, mx):\n",
    "    \"\"\"\n",
    "    Clamps a number between two values.\n",
    "    :param num: The number to clamp.\n",
    "    :param mn: The minimum value.\n",
    "    :param mx: The maximum value.\n",
    "    :return: The clamped number.\n",
    "    \"\"\"\n",
    "    return max(min(num, mx), mn)\n",
    "\n",
    "\n",
    "seg_dir = '/data/projects/TMOR/data/Deeplearning/'\n",
    "#indices = []\n",
    "for subj_id in os.listdir(seg_dir):\n",
    "    #extrasct the correct id from the subjects\n",
    "    # Define paths to the segmentation and regular t1 postprocessed files for this subject\n",
    "    seg_glob = os.path.join(seg_dir, f'{subj_id}', f'seg.nii.gz')\n",
    "    reg_glob = os.path.join(seg_dir, f'{subj_id}', f't1_gd.nii.gz')\n",
    "    seg_paths = glob.glob(seg_glob)\n",
    "    reg_paths = glob.glob(reg_glob)\n",
    "    # Loop through all matching segmentation and registration files\n",
    "    for seg, reg in zip(seg_paths, reg_paths):\n",
    "        if os.path.exists(seg) and os.path.exists(reg):\n",
    "            mask = nib.load(seg)\n",
    "            vol_mask = mask.get_fdata()\n",
    "            for label in np.unique(vol_mask):\n",
    "                if label != 0:\n",
    "                    label_indices = np.argwhere(vol_mask == label)\n",
    "                    if len(label_indices) > 125:\n",
    "                        indices = label_indices\n",
    "                        X_min, X_max = np.min(indices[:, 0]), np.max(indices[:, 0])\n",
    "                        Y_min, Y_max = np.min(indices[:, 1]), np.max(indices[:, 1])\n",
    "                        Z_min, Z_max = np.min(indices[:, 2]), np.max(indices[:, 2])\n",
    "\n",
    "                        mean_x = (X_min + X_max) // 2\n",
    "                        mean_y = (Y_min + Y_max) // 2\n",
    "                        mean_z = (Z_min + Z_max) // 2\n",
    "                        ###############################\n",
    "                        d_x = D_x_max\n",
    "                        d_y = D_y_max\n",
    "                        d_z = D_z_max\n",
    "                        ##################################\n",
    "                        x_start = clamp(mean_x - d_x // 2, 0, vol_mask.shape[0])\n",
    "                        x_end = clamp(mean_x + d_x // 2, 0, vol_mask.shape[0])\n",
    "\n",
    "                        y_start = clamp(mean_y - d_y // 2, 0, vol_mask.shape[1])\n",
    "                        y_end = clamp(mean_y + d_y // 2, 0, vol_mask.shape[1])\n",
    "\n",
    "                        z_start = clamp(mean_z - d_z // 2, 0, vol_mask.shape[2])\n",
    "                        z_end = clamp(mean_z + d_z // 2, 0, vol_mask.shape[2])\n",
    "\n",
    "                        tumor_cutout = vol_mask[x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "                        ###################################\n",
    "                        tensor = np.zeros([d_x, d_y, d_z])\n",
    "                        # Define the position of the bounding box in the tensor\n",
    "                        tx_start = abs(mean_x - d_x // 2) if mean_x - d_x // 2 < 0 else 0\n",
    "                        tx_end = tumor_cutout.shape[0] + tx_start\n",
    "\n",
    "                        ty_start = abs(mean_y - d_y // 2) if mean_y - d_y // 2 < 0 else 0\n",
    "                        ty_end = tumor_cutout.shape[1] + ty_start\n",
    "\n",
    "                        tz_start = abs(mean_z - d_z // 2) if mean_z - d_z // 2 < 0 else 0\n",
    "                        tz_end = tumor_cutout.shape[2] + tz_start\n",
    "\n",
    "                        # Place the bounding box in the tensor\n",
    "                        tensor[tx_start:tx_end, ty_start:ty_end, tz_start:tz_end] = tumor_cutout\n",
    "                        output_dir = os.path.join(seg_dir, 'B', subj_id)\n",
    "                        os.makedirs(output_dir, exist_ok=True)\n",
    "                         # Save the seg_partitioned into a file\n",
    "                        output_path = os.path.join(output_dir, f'{label}seg_seg_.nii.gz')\n",
    "                        nib.save(nib.Nifti1Image(tumor_cutout, mask.affine), output_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T12:35:46.117116Z",
     "end_time": "2023-07-06T12:36:35.239395Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "df2 = df[['subjid']].join(df['label']).join(df['labels'])\n",
    "df2.to_excel('final_labels.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T18:58:57.451416Z",
     "end_time": "2023-07-06T18:58:57.494919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "class BrainSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.read_excel(labels_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.X self.X_test, self.y_train, self.y_test = self.split_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform is None:\n",
    "            # Load the mask directly\n",
    "            seg_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 'seg.nii.gz')\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 't1_gd.nii.gz')\n",
    "            label = self.y_train[idx]\n",
    "            data = nib.load(img_path).get_fdata()\n",
    "            mask = nib.load(seg_path).get_fdata()\n",
    "        else:\n",
    "            # Apply the transformation to the mask\n",
    "            seg_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 'seg.nii.gz')\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 't1_gd.nii.gz')\n",
    "            label = self.y_train[idx]\n",
    "            mask = nib.load(seg_path).get_fdata()\n",
    "            data = nib.load(img_path).get_fdata()\n",
    "\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "        label = torch.tensor(label).long()\n",
    "\n",
    "        return mask, data,label\n",
    "\n",
    "    def split_data(self):\n",
    "        X = self.img_labels.iloc[:, 0].values\n",
    "        y = self.img_labels.iloc[:, 2].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "img_dir = '/data/projects/TMOR/data/Deeplearning/'\n",
    "labels_file = 'labels_DL.xlsx'\n",
    "dataset = BrainSegmentationDataset(img_dir, labels_file)\n",
    "\n",
    "# Access the X_train list\n",
    "print(dataset.X_train.size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T19:05:32.452442Z",
     "end_time": "2023-06-19T19:05:32.490471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BrainSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.read_excel(labels_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.X, self.y, self.seg_paths = self.load_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform is None:\n",
    "            seg_path = self.seg_paths[idx]\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 't1_gd.nii.gz')\n",
    "            label = self.y[idx]\n",
    "            mask = nib.load(seg_path).get_fdata()\n",
    "            data = nib.load(img_path).get_fdata()\n",
    "        else:\n",
    "            seg_path = self.seg_paths[idx]\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 't1_gd.nii.gz')\n",
    "            label = self.y[idx]\n",
    "            mask = nib.load(seg_path).get_fdata()\n",
    "            data = nib.load(img_path).get_fdata()\n",
    "\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "        data = torch.from_numpy(data).unsqueeze(0)\n",
    "        label = torch.tensor(label).long()\n",
    "\n",
    "        return mask, data, label\n",
    "\n",
    "    def load_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        seg_paths = []\n",
    "\n",
    "        for idx in range(len(self.img_labels)):\n",
    "            seg_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 'seg.nii.gz')\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], 't1_gd.nii.gz')\n",
    "            label = self.img_labels.iloc[idx, 2]\n",
    "            seg_paths.append(seg_path)\n",
    "            mask = nib.load(seg_path).get_fdata()\n",
    "            data = nib.load(img_path).get_fdata()\n",
    "\n",
    "            X.append(data)\n",
    "            y.append(label)\n",
    "\n",
    "        return X, y, seg_paths\n",
    "\n",
    "\n",
    "img_dir = '/data/projects/TMOR/data/VeryFinal/'\n",
    "labels_file = 'final_labels.xlsx'\n",
    "dataset = BrainSegmentationDataset(img_dir, labels_file)\n",
    "\n",
    "# Access the X, y, and seg_paths\n",
    "X_data = dataset.X\n",
    "y_data = dataset.y\n",
    "seg_paths = dataset.seg_paths\n",
    "\n",
    "# Get the length of the dataset\n",
    "print(len(dataset))\n",
    "\n",
    "# Get an example item from the dataset\n",
    "mask, data, label = dataset[0]\n",
    "print(mask.shape)\n",
    "print(data.shape)\n",
    "print(label)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "        subjid  label  labels\n0       Oslo01      1       0\n1       Oslo01      2       0\n4       Oslo02      4       1\n5       Oslo02      5       1\n7       Oslo03      1       0\n...        ...    ...     ...\n2408  Stan_328      1       1\n2415  Stan_328      8       1\n2418  Stan_328     11       1\n2419  Stan_328     12       1\n2427  Stan_338      4       1\n\n[438 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subjid</th>\n      <th>label</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Oslo01</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Oslo01</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oslo02</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Oslo02</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Oslo03</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2408</th>\n      <td>Stan_328</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2415</th>\n      <td>Stan_328</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2418</th>\n      <td>Stan_328</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2419</th>\n      <td>Stan_328</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2427</th>\n      <td>Stan_338</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>438 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T18:59:17.838592Z",
     "end_time": "2023-07-06T18:59:17.844538Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    4    5    7    9   11   13   14   20   21   22   23   24\n",
      "   26   27   28   35   36   37   38   39   40   41   42   43   44   45\n",
      "   46   56   58   59   64   65   67   68   69   70   72   73   74   75\n",
      "   76   79   80   81   82   83   85   86   87   88   89   93   94   96\n",
      "   97   99  101  102  104  107  108  110  111  112  113  115  116  120\n",
      "  121  122  123  124  127  129  130  131  132  133  134  135  136  137\n",
      "  140  141  142  145  146  147  155  160  161  163  173  174  175  177\n",
      "  178  179  181  182  184  185  187  192  197  202  207  217  218  262\n",
      "  281  293  300  305  308  315  316  319  320  322  325  329  330  338\n",
      "  340  341  351  352  379  380  387  397  399  400  402  403  406  407\n",
      "  408  414  421  422  447  497  578  607  609  613  644  661  662  663\n",
      "  665  666  667  668  678  683  684  686  689  691  693  695  702  710\n",
      "  727  730  734  735  751  753  757  769  773  774  775  776  777  778\n",
      "  783  796  804  805  806  822  823  824  828  830  844  847  853  856\n",
      "  857  860  883  886  888  889  890  893  895  900  901  903  904  905\n",
      "  909  910  915  916  925  928  929  941  943  953  957  966  968  984\n",
      "  994 1004 1005 1009 1014 1016 1023 1035 1066 1067 1077 1078 1116 1135\n",
      " 1136 1142 1153 1154 1160 1162 1171 1175 1180 1181 1186 1188 1202 1203\n",
      " 1204 1209 1224 1226 1229 1237 1239 1263 1265 1284 1287 1296 1299 1301\n",
      " 1303 1306 1308 1328 1331 1345 1386 1390 1393 1398 1423 1437 1447 1468\n",
      " 1481 1483 1487 1489 1500 1504 1514 1515 1516 1517 1518 1519 1523 1524\n",
      " 1538 1563 1564 1569 1571 1572 1573 1574 1577 1578 1579 1585 1592 1595\n",
      " 1597 1598 1599 1600 1602 1606 1607 1609 1694 1695 1700 1704 1709 1710\n",
      " 1711 1713 1714 1718 1733 1736 1738 1741 1744 1769 1771 1772 1775 1778\n",
      " 1779 1781 1789 1790 1791 1792 1811 1824 1830 1836 1847 1868 1917 1918\n",
      " 1921 1922 1923 1928 1945 1947 1950 1952 1954 1966 1967 1970 1972 1973\n",
      " 1979 1985 1989 1991 2001 2005 2025 2095 2106 2128 2144 2148 2153 2154\n",
      " 2161 2167 2174 2179 2182 2183 2185 2187 2188 2194 2195 2196 2197 2201\n",
      " 2202 2204 2213 2224 2225 2226 2228 2231 2232 2234 2235 2238 2240 2241\n",
      " 2243 2244 2247 2249 2250 2319 2322 2323 2324 2325 2331 2349 2359 2361\n",
      " 2364 2366 2369 2371 2375 2377 2379 2380 2387 2389 2390 2401 2408 2415\n",
      " 2418 2419 2427]/['Oslo01' 'Oslo01' 'Oslo02' 'Oslo02' 'Oslo03' 'Oslo03' 'Oslo04' 'Oslo06'\n",
      " 'Oslo07' 'Oslo08' 'Oslo09' 'Oslo09' 'Oslo10' 'Oslo11' 'Oslo12' 'Oslo13'\n",
      " 'Oslo14' 'Oslo17' 'Oslo18' 'Oslo18' 'Oslo18' 'Oslo19' 'Oslo20' 'Oslo20'\n",
      " 'Oslo21' 'Oslo22' 'Oslo23' 'Oslo24' 'Oslo24' 'Oslo25' 'Oslo26' 'Oslo26'\n",
      " 'Oslo28' 'Oslo29' 'Oslo30' 'Oslo30' 'Oslo31' 'Oslo31' 'Oslo32' 'Oslo32'\n",
      " 'Oslo33' 'Oslo33' 'Oslo34' 'Oslo35' 'Oslo36' 'Oslo37' 'Oslo37' 'Oslo38'\n",
      " 'Oslo38' 'Oslo39' 'Oslo40' 'Oslo41' 'Oslo41' 'Oslo42' 'Oslo43' 'Oslo43'\n",
      " 'Oslo43' 'Oslo44' 'Oslo45' 'Oslo45' 'Oslo46' 'Oslo47' 'Oslo48' 'Oslo48'\n",
      " 'Oslo49' 'Oslo49' 'Oslo49' 'Oslo50' 'Oslo51' 'Oslo52' 'Oslo52' 'Oslo53'\n",
      " 'Oslo53' 'Oslo54' 'Oslo55' 'Oslo56' 'Oslo59' 'Oslo60' 'Oslo61' 'Oslo62'\n",
      " 'Oslo63' 'Oslo63' 'Oslo63' 'Oslo63' 'Oslo65' 'Oslo65' 'Oslo65' 'Stan_005'\n",
      " 'Stan_005' 'Stan_005' 'Stan_009' 'Stan_009' 'Stan_010' 'Stan_010'\n",
      " 'Stan_014' 'Stan_014' 'Stan_014' 'Stan_014' 'Stan_014' 'Stan_014'\n",
      " 'Stan_016' 'Stan_016' 'Stan_016' 'Stan_016' 'Stan_019' 'Stan_019'\n",
      " 'Stan_019' 'Stan_021' 'Stan_021' 'Stan_021' 'Stan_024' 'Stan_024'\n",
      " 'Stan_024' 'Stan_026' 'Stan_026' 'Stan_028' 'Stan_028' 'Stan_032'\n",
      " 'Stan_032' 'Stan_032' 'Stan_033' 'Stan_036' 'Stan_037' 'Stan_037'\n",
      " 'Stan_038' 'Stan_039' 'Stan_039' 'Stan_039' 'Stan_041' 'Stan_041'\n",
      " 'Stan_045' 'Stan_045' 'Stan_047' 'Stan_047' 'Stan_049' 'Stan_049'\n",
      " 'Stan_049' 'Stan_049' 'Stan_049' 'Stan_049' 'Stan_049' 'Stan_051'\n",
      " 'Stan_051' 'Stan_051' 'Stan_052' 'Stan_052' 'Stan_052' 'Stan_053'\n",
      " 'Stan_053' 'Stan_053' 'Stan_054' 'Stan_055' 'Stan_055' 'Stan_055'\n",
      " 'Stan_055' 'Stan_055' 'Stan_055' 'Stan_055' 'Stan_055' 'Stan_058'\n",
      " 'Stan_058' 'Stan_058' 'Stan_058' 'Stan_058' 'Stan_058' 'Stan_058'\n",
      " 'Stan_059' 'Stan_059' 'Stan_064' 'Stan_064' 'Stan_064' 'Stan_064'\n",
      " 'Stan_064' 'Stan_064' 'Stan_064' 'Stan_064' 'Stan_065' 'Stan_065'\n",
      " 'Stan_065' 'Stan_065' 'Stan_065' 'Stan_065' 'Stan_066' 'Stan_066'\n",
      " 'Stan_066' 'Stan_066' 'Stan_066' 'Stan_068' 'Stan_068' 'Stan_068'\n",
      " 'Stan_069' 'Stan_069' 'Stan_072' 'Stan_074' 'Stan_081' 'Stan_087'\n",
      " 'Stan_087' 'Stan_089' 'Stan_096' 'Stan_096' 'Stan_096' 'Stan_096'\n",
      " 'Stan_096' 'Stan_098' 'Stan_098' 'Stan_099' 'Stan_099' 'Stan_099'\n",
      " 'Stan_100' 'Stan_100' 'Stan_101' 'Stan_101' 'Stan_102' 'Stan_107'\n",
      " 'Stan_107' 'Stan_107' 'Stan_107' 'Stan_107' 'Stan_107' 'Stan_107'\n",
      " 'Stan_107' 'Stan_111' 'Stan_111' 'Stan_120' 'Stan_120' 'Stan_120'\n",
      " 'Stan_120' 'Stan_120' 'Stan_120' 'Stan_120' 'Stan_120' 'Stan_120'\n",
      " 'Stan_120' 'Stan_120' 'Stan_120' 'Stan_120' 'Stan_120' 'Stan_121'\n",
      " 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121'\n",
      " 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121'\n",
      " 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121'\n",
      " 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121' 'Stan_121'\n",
      " 'Stan_122' 'Stan_123' 'Stan_123' 'Stan_123' 'Stan_123' 'Stan_126'\n",
      " 'Stan_127' 'Stan_132' 'Stan_132' 'Stan_134' 'Stan_134' 'Stan_134'\n",
      " 'Stan_134' 'Stan_134' 'Stan_134' 'Stan_136' 'Stan_136' 'Stan_136'\n",
      " 'Stan_136' 'Stan_136' 'Stan_136' 'Stan_136' 'Stan_142' 'Stan_142'\n",
      " 'Stan_144' 'Stan_144' 'Stan_144' 'Stan_144' 'Stan_144' 'Stan_144'\n",
      " 'Stan_148' 'Stan_149' 'Stan_165' 'Stan_170' 'Stan_170' 'Stan_170'\n",
      " 'Stan_171' 'Stan_171' 'Stan_173' 'Stan_173' 'Stan_173' 'Stan_173'\n",
      " 'Stan_173' 'Stan_176' 'Stan_176' 'Stan_176' 'Stan_177' 'Stan_177'\n",
      " 'Stan_177' 'Stan_183' 'Stan_184' 'Stan_185' 'Stan_185' 'Stan_185'\n",
      " 'Stan_197' 'Stan_197' 'Stan_197' 'Stan_203' 'Stan_203' 'Stan_203'\n",
      " 'Stan_203' 'Stan_203' 'Stan_203' 'Stan_203' 'Stan_225' 'Stan_225'\n",
      " 'Stan_225' 'Stan_227' 'Stan_230' 'Stan_244' 'Stan_244' 'Stan_244'\n",
      " 'Stan_244' 'Stan_244' 'Stan_246' 'Stan_246' 'Stan_251' 'Stan_251'\n",
      " 'Stan_251' 'Stan_251' 'Stan_252' 'Stan_252' 'Stan_252' 'Stan_252'\n",
      " 'Stan_252' 'Stan_252' 'Stan_257' 'Stan_257' 'Stan_257' 'Stan_260'\n",
      " 'Stan_260' 'Stan_265' 'Stan_266' 'Stan_266' 'Stan_266' 'Stan_266'\n",
      " 'Stan_266' 'Stan_266' 'Stan_266' 'Stan_266' 'Stan_266' 'Stan_266'\n",
      " 'Stan_266' 'Stan_266' 'Stan_266' 'Stan_266' 'Stan_266' 'Stan_266'\n",
      " 'Stan_274' 'Stan_283' 'Stan_283' 'Stan_283' 'Stan_283' 'Stan_283'\n",
      " 'Stan_283' 'Stan_283' 'Stan_283' 'Stan_283' 'Stan_283' 'Stan_285'\n",
      " 'Stan_289' 'Stan_289' 'Stan_289' 'Stan_289' 'Stan_289' 'Stan_289'\n",
      " 'Stan_290' 'Stan_291' 'Stan_291' 'Stan_297' 'Stan_297' 'Stan_297'\n",
      " 'Stan_303' 'Stan_307' 'Stan_307' 'Stan_307' 'Stan_307' 'Stan_307'\n",
      " 'Stan_307' 'Stan_311' 'Stan_312' 'Stan_313' 'Stan_313' 'Stan_313'\n",
      " 'Stan_313' 'Stan_313' 'Stan_313' 'Stan_313' 'Stan_313' 'Stan_315'\n",
      " 'Stan_315' 'Stan_315' 'Stan_315' 'Stan_315' 'Stan_315' 'Stan_316'\n",
      " 'Stan_318' 'Stan_318' 'Stan_318' 'Stan_318' 'Stan_319' 'Stan_319'\n",
      " 'Stan_319' 'Stan_319' 'Stan_319' 'Stan_319' 'Stan_323' 'Stan_323'\n",
      " 'Stan_323' 'Stan_323' 'Stan_328' 'Stan_328' 'Stan_328' 'Stan_328'\n",
      " 'Stan_338']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/data/projects/TMOR/data/VeryFinal/[/seg.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/site-packages/nibabel/loadsave.py:87\u001B[0m, in \u001B[0;36mload\u001B[0;34m(filename, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 87\u001B[0m     stat_result \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/data/projects/TMOR/data/VeryFinal/[/seg.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[205], line 73\u001B[0m\n\u001B[1;32m     70\u001B[0m labels_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinal_labels.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m#transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mBrainSegmentationDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m data_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[205], line 8\u001B[0m, in \u001B[0;36mBrainSegmentationDataset.__init__\u001B[0;34m(self, img_dir, labels_file, transform, target_transform)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;241m=\u001B[39m transform\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;241m=\u001B[39m target_transform\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[205], line 42\u001B[0m, in \u001B[0;36mBrainSegmentationDataset.load_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     40\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_labels\u001B[38;5;241m.\u001B[39miloc[:, \u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28mprint\u001B[39m(X)\n\u001B[0;32m---> 42\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, y\n",
      "Cell \u001B[0;32mIn[205], line 54\u001B[0m, in \u001B[0;36mBrainSegmentationDataset.process_images\u001B[0;34m(self, folder_names)\u001B[0m\n\u001B[1;32m     52\u001B[0m t1_gd_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_dir, folder_name, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt1_gd.nii.gz\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     53\u001B[0m t1_pre_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_dir, folder_name, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt1_pre.nii.gz\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 54\u001B[0m mask_1 \u001B[38;5;241m=\u001B[39m \u001B[43mnib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseg_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m mask \u001B[38;5;241m=\u001B[39m mask_1\u001B[38;5;241m.\u001B[39mget_fdata()\n\u001B[1;32m     56\u001B[0m data_1 \u001B[38;5;241m=\u001B[39m nib\u001B[38;5;241m.\u001B[39mload(t1_gd_path)\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/site-packages/nibabel/loadsave.py:89\u001B[0m, in \u001B[0;36mload\u001B[0;34m(filename, **kwargs)\u001B[0m\n\u001B[1;32m     87\u001B[0m     stat_result \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstat(filename)\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[0;32m---> 89\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo such file or no access: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stat_result\u001B[38;5;241m.\u001B[39mst_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ImageFileError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmpty file: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: No such file or no access: '/data/projects/TMOR/data/VeryFinal/[/seg.nii.gz'"
     ]
    }
   ],
   "source": [
    "class BrainSegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.read_excel(labels_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.X, self.y = self.load_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the mask directly\n",
    "        seg_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], self.img_labels.iloc[idx, 1],'seg.nii.gz')\n",
    "        t1_gd_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], self.img_labels.iloc[idx, 1], 't1_gd.nii.gz')\n",
    "        t1_pre_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0], self.img_labels.iloc[idx, 1], 't1_pre.nii.gz')\n",
    "        mask_1 = nib.load(seg_path)\n",
    "        mask = mask_1.get_fdata()\n",
    "        data_1 = nib.load(t1_gd_path)\n",
    "        t1_gd = data_1.get_fdata()\n",
    "        data_2 = nib.load(t1_pre_path)\n",
    "        t1_pre = data_2.get_fdata()\n",
    "        label = self.y[idx]\n",
    "\n",
    "\n",
    "        t1_gd = torch.from_numpy(t1_gd).unsqueeze(0)\n",
    "        t1_pre = torch.from_numpy(t1_pre).unsqueeze(0)\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "        label = torch.tensor(label).long()\n",
    "\n",
    "        return mask, t1_gd, t1_pre,label\n",
    "\n",
    "    def load_data(self):\n",
    "        subjid = self.img_labels.iloc[:, 0].values\n",
    "        label = self.img_labels.iloc[:, 1].values\n",
    "        #X = str(os.path.join(self.img_dir, str(subjid), str(label)))\n",
    "        #X = str(os.path.join(self.img_dir, str(subjid[i]), str(label) for i in range(len(subjid))))\n",
    "        X = str(subjid) + str('/') + str(label)\n",
    "        y = self.img_labels.iloc[:, 2].values\n",
    "        print(X)\n",
    "        X = self.process_images(X)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def process_images(self, folder_names):\n",
    "        image_tensors = []\n",
    "\n",
    "        for folder_name in folder_names:\n",
    "            # Load the mask directly\n",
    "            seg_path = os.path.join(self.img_dir, folder_name, 'seg.nii.gz')\n",
    "            t1_gd_path = os.path.join(self.img_dir, folder_name, 't1_gd.nii.gz')\n",
    "            t1_pre_path = os.path.join(self.img_dir, folder_name, 't1_pre.nii.gz')\n",
    "            mask_1 = nib.load(seg_path)\n",
    "            mask = mask_1.get_fdata()\n",
    "            data_1 = nib.load(t1_gd_path)\n",
    "            t1_gd = data_1.get_fdata()\n",
    "            data_2 = nib.load(t1_pre_path)\n",
    "            t1_pre = data_2.get_fdata()\n",
    "\n",
    "            t1_gd_tensor = torch.from_numpy(t1_gd).unsqueeze(0)\n",
    "            t1_pre_tensor = torch.from_numpy(t1_pre).unsqueeze(0)\n",
    "            mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "            image_tensors.append([mask_tensor, t1_gd_tensor, t1_pre_tensor])\n",
    "\n",
    "        return image_tensors\n",
    "\n",
    "img_dir = '/data/projects/TMOR/data/VeryFinal/'\n",
    "labels_file = 'final_labels.xlsx'\n",
    "#transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "\n",
    "dataset = BrainSegmentationDataset(img_dir, labels_file, transform=None)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T19:03:16.415674Z",
     "end_time": "2023-07-06T19:03:16.455556Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "'Oslo01/2'"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T15:00:11.537271Z",
     "end_time": "2023-07-07T15:00:11.577336Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "outputs": [],
   "source": [
    "img_dir = '/data/projects/TMOR/data/Deeplearning/'\n",
    "labels_file = 'labels_DL.xlsx'\n",
    "transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "\n",
    "dataset = BrainSegmentationDataset(img_dir,labels_file, transform=None)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T19:35:17.695217Z",
     "end_time": "2023-06-19T19:36:00.426919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 135, 159, 132])"
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = dataset.X_train, dataset.X_test, dataset.y_train, dataset.y_test\n",
    "\n",
    "X_train[6].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T18:08:05.246161Z",
     "end_time": "2023-06-19T18:08:05.294773Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/projects/TMOR/data/Deeplearning/Oslo01/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo01/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo02/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo02/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo03/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo03/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo04/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo06/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo07/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo08/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo09/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo09/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo10/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo11/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo12/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo13/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo14/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo17/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo18/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo18/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo18/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo19/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo20/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo20/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo21/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo22/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo23/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo24/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo24/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo25/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo26/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo26/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo28/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo29/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo30/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo30/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo31/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo31/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo32/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo32/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo33/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo33/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo34/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo35/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo36/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo37/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo37/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo38/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo38/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo39/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo40/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo41/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo41/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo42/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo43/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo43/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo43/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo44/seg.nii.gz\n",
      "/data/projects/TMOR/data/Deeplearning/Oslo45/seg.nii.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[403], line 31\u001B[0m\n\u001B[1;32m     27\u001B[0m     image_tensors\u001B[38;5;241m.\u001B[39mappend((data_tensor, mask_tensor))\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m image_tensors\n\u001B[0;32m---> 31\u001B[0m processed_images \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[403], line 21\u001B[0m, in \u001B[0;36mprocess_images\u001B[0;34m(img_dir, labels_file)\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(seg_path)\n\u001B[1;32m     20\u001B[0m     img_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(img_dir, image_name, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt1_gd.nii.gz\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 21\u001B[0m     mask \u001B[38;5;241m=\u001B[39m \u001B[43mnib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseg_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_fdata\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     data \u001B[38;5;241m=\u001B[39m nib\u001B[38;5;241m.\u001B[39mload(img_path)\u001B[38;5;241m.\u001B[39mget_fdata()\n\u001B[1;32m     24\u001B[0m data_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(data)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/site-packages/nibabel/dataobj_images.py:368\u001B[0m, in \u001B[0;36mDataobjImage.get_fdata\u001B[0;34m(self, caching, dtype)\u001B[0m\n\u001B[1;32m    364\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fdata_cache\n\u001B[1;32m    365\u001B[0m \u001B[38;5;66;03m# Always return requested data type\u001B[39;00m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001B[39;00m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;66;03m# during scaling\u001B[39;00m\n\u001B[0;32m--> 368\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m caching \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfill\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    370\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fdata_cache \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/site-packages/nibabel/arrayproxy.py:426\u001B[0m, in \u001B[0;36mArrayProxy.__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;124;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001B[39;00m\n\u001B[1;32m    407\u001B[0m \n\u001B[1;32m    408\u001B[0m \u001B[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;124;03m        Scaled image data with type `dtype`.\u001B[39;00m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 426\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_scaled\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mslicer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    428\u001B[0m         arr \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/site-packages/nibabel/arrayproxy.py:393\u001B[0m, in \u001B[0;36mArrayProxy._get_scaled\u001B[0;34m(self, dtype, slicer)\u001B[0m\n\u001B[1;32m    391\u001B[0m     scl_inter \u001B[38;5;241m=\u001B[39m scl_inter\u001B[38;5;241m.\u001B[39mastype(use_dtype)\n\u001B[1;32m    392\u001B[0m \u001B[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001B[39;00m\n\u001B[0;32m--> 393\u001B[0m scaled \u001B[38;5;241m=\u001B[39m apply_read_scaling(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_unscaled\u001B[49m\u001B[43m(\u001B[49m\u001B[43mslicer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mslicer\u001B[49m\u001B[43m)\u001B[49m, scl_slope, scl_inter)\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    395\u001B[0m     scaled \u001B[38;5;241m=\u001B[39m scaled\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mpromote_types(scaled\u001B[38;5;241m.\u001B[39mdtype, dtype), copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/site-packages/nibabel/arrayproxy.py:363\u001B[0m, in \u001B[0;36mArrayProxy._get_unscaled\u001B[0;34m(self, slicer)\u001B[0m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m canonical_slicers(slicer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shape, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m==\u001B[39m canonical_slicers(\n\u001B[1;32m    360\u001B[0m     (), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shape, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    361\u001B[0m ):\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_fileobj() \u001B[38;5;28;01mas\u001B[39;00m fileobj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m--> 363\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray_from_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfileobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m            \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_offset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m            \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mmap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_fileobj() \u001B[38;5;28;01mas\u001B[39;00m fileobj:\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fileslice(\n\u001B[1;32m    373\u001B[0m         fileobj,\n\u001B[1;32m    374\u001B[0m         slicer,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    379\u001B[0m         lock\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock,\n\u001B[1;32m    380\u001B[0m     )\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/site-packages/nibabel/volumeutils.py:454\u001B[0m, in \u001B[0;36marray_from_file\u001B[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(infile, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreadinto\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    453\u001B[0m     data_bytes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(n_bytes)\n\u001B[0;32m--> 454\u001B[0m     n_read \u001B[38;5;241m=\u001B[39m \u001B[43minfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_bytes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m     needs_copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/gzip.py:300\u001B[0m, in \u001B[0;36mGzipFile.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    298\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01merrno\u001B[39;00m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(errno\u001B[38;5;241m.\u001B[39mEBADF, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread() on write-only GzipFile object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 300\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/_compression.py:68\u001B[0m, in \u001B[0;36mDecompressReader.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreadinto\u001B[39m(\u001B[38;5;28mself\u001B[39m, b):\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b) \u001B[38;5;28;01mas\u001B[39;00m view, view\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m byte_view:\n\u001B[0;32m---> 68\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbyte_view\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m         byte_view[:\u001B[38;5;28mlen\u001B[39m(data)] \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data)\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/gzip.py:509\u001B[0m, in \u001B[0;36m_GzipReader.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    505\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buf \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    506\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompressed file ended before the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    507\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend-of-stream marker was reached\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 509\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add_read_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[43muncompress\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(uncompress)\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m uncompress\n",
      "File \u001B[0;32m~/.conda/envs/secondenv/lib/python3.9/gzip.py:514\u001B[0m, in \u001B[0;36m_GzipReader._add_read_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_add_read_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m--> 514\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_crc \u001B[38;5;241m=\u001B[39m \u001B[43mzlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcrc32\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_crc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream_size \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlen\u001B[39m(data)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataFrame called \"data\"\n",
    "# Features are stored in columns X1, X2, X3, ...\n",
    "# The target variable is stored in column 'y'\n",
    "\n",
    "X = new_df.drop(['Labels', 'Tumor'],axis=1)  # Features\n",
    "y = new_df['Labels']  # Target variable\n",
    "# Random split into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train\n",
    "\n",
    "img_dir = '/data/projects/TMOR/data/Deeplearning/'\n",
    "labels_file = pd.read_excel('labels_DL.xlsx')\n",
    "\n",
    "def process_images(img_dir, labels_file):\n",
    "    image_tensors = []\n",
    "    pene = list(labels_file.iloc[:, 0])\n",
    "    for image_name in pene:\n",
    "        seg_path = os.path.join(img_dir, image_name, 'seg.nii.gz')\n",
    "        print(seg_path)\n",
    "        img_path = os.path.join(img_dir, image_name, 't1_gd.nii.gz')\n",
    "        mask = nib.load(seg_path).get_fdata()\n",
    "        data = nib.load(img_path).get_fdata()\n",
    "\n",
    "    data_tensor = torch.from_numpy(data).unsqueeze(0)\n",
    "    mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "    image_tensors.append((data_tensor, mask_tensor))\n",
    "\n",
    "    return image_tensors\n",
    "\n",
    "processed_images = process_images(img_dir, labels_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T18:44:25.135265Z",
     "end_time": "2023-06-19T18:44:55.162618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "outputs": [
    {
     "data": {
      "text/plain": "Subjid    Stan_319\nName: 2369, dtype: object"
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[4, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T18:55:18.616208Z",
     "end_time": "2023-06-19T18:55:18.656019Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
